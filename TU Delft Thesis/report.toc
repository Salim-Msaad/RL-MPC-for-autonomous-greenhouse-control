\contentsline {chapter}{Preface}{i}{chapter*.1}%
\contentsline {chapter}{Summary}{ii}{chapter*.2}%
\contentsline {chapter}{Nomenclature}{v}{chapter*.4}%
\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}Problem Statement}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Thesis Contribution}{4}{section.1.2}%
\contentsline {section}{\numberline {1.3}Recent and Related Developments}{4}{section.1.3}%
\contentsline {section}{\numberline {1.4}Thesis Outline}{5}{section.1.4}%
\contentsline {chapter}{\numberline {2}Background}{6}{chapter.2}%
\contentsline {section}{\numberline {2.1}Greenhouse Model}{6}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Model Description}{7}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Model State Equations}{8}{subsection.2.1.2}%
\contentsline {paragraph}{State Equations}{8}{subsection.2.1.2}%
\contentsline {paragraph}{Output Measurement Equations}{9}{equation.2.1.16}%
\contentsline {subsection}{\numberline {2.1.3}Model uncertainty}{11}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Optimisation Goal}{12}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}Reinforcement Learning}{13}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The RL problem}{14}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Q learning}{16}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Policy Optimization}{16}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Actor-Critic}{16}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}SAC}{17}{subsection.2.2.5}%
\contentsline {section}{\numberline {2.3}MPC}{18}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}The General MPC problem}{19}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Economic Model Predictive Control (EMPC)}{20}{subsection.2.3.2}%
\contentsline {chapter}{\numberline {3}Reinforcement Learning Setup}{22}{chapter.3}%
\contentsline {section}{\numberline {3.1}Environment Description}{22}{section.3.1}%
\contentsline {paragraph}{Observation Space}{22}{section.3.1}%
\contentsline {paragraph}{Action Space}{23}{equation.3.1.3}%
\contentsline {paragraph}{Initial Conditions}{23}{equation.3.1.3}%
\contentsline {paragraph}{Reward Function}{23}{equation.3.1.4}%
\contentsline {section}{\numberline {3.2}Experimental Setup}{24}{section.3.2}%
\contentsline {paragraph}{Weather Data}{25}{equation.3.2.7}%
\contentsline {paragraph}{Deterministic and Stochastic Case}{25}{figure.caption.11}%
\contentsline {paragraph}{Performance Metrics}{25}{figure.caption.11}%
\contentsline {section}{\numberline {3.3}Hyper-parameter Tuning}{26}{section.3.3}%
\contentsline {paragraph}{Activation Function}{26}{table.caption.12}%
\contentsline {paragraph}{Discount Factor}{26}{table.caption.12}%
\contentsline {section}{\numberline {3.4}Deterministic Results}{26}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Discount Factor}{26}{subsection.3.4.1}%
\contentsline {paragraph}{Performance}{27}{figure.caption.13}%
\contentsline {paragraph}{Value Function}{27}{figure.caption.13}%
\contentsline {subsection}{\numberline {3.4.2}Activation Function}{29}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}Final Results and Conclusion}{29}{subsection.3.4.3}%
\contentsline {section}{\numberline {3.5}Stochastic Results}{31}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Conclusion}{32}{subsection.3.5.1}%
\contentsline {section}{\numberline {3.6}Trained Value Function}{32}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Temporal Difference Learning}{32}{subsection.3.6.1}%
\contentsline {paragraph}{Obtaining Data}{33}{subsection.3.6.1}%
\contentsline {paragraph}{Training}{34}{figure.caption.23}%
\contentsline {subsection}{\numberline {3.6.2}Expected Return Learning}{35}{subsection.3.6.2}%
\contentsline {paragraph}{Obtaining Data}{35}{subsection.3.6.2}%
\contentsline {paragraph}{Training}{36}{equation.3.6.13}%
\contentsline {paragraph}{Experimental Setup}{36}{equation.3.6.14}%
\contentsline {subsection}{\numberline {3.6.3}Results}{38}{subsection.3.6.3}%
\contentsline {section}{\numberline {3.7}Conclusion}{42}{section.3.7}%
\contentsline {chapter}{\numberline {4}Model Predictive Control Setup}{43}{chapter.4}%
\contentsline {section}{\numberline {4.1}Greenhouse MPC problem formulation}{43}{section.4.1}%
\contentsline {paragraph}{Simulation Setup}{44}{equation.4.1.3}%
\contentsline {section}{\numberline {4.2}Deterministic Results}{44}{section.4.2}%
\contentsline {section}{\numberline {4.3}Stochastic Results}{46}{section.4.3}%
\contentsline {section}{\numberline {4.4}Conclusion}{48}{section.4.4}%
\contentsline {chapter}{\numberline {5}Deterministic RL-MPC}{49}{chapter.5}%
\contentsline {section}{\numberline {5.1}Implementation}{49}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}RL-MPC problem formulations}{49}{subsection.5.1.1}%
\contentsline {paragraph}{Implementation RL-MPC 1}{49}{subsection.5.1.1}%
\contentsline {paragraph}{Implementation RL-MPC 2}{50}{equation.5.1.5}%
\contentsline {paragraph}{Implementation RL-MPC 3}{51}{equation.5.1.7}%
\contentsline {paragraph}{Implementation RL-MPC 4}{51}{equation.5.1.8}%
\contentsline {paragraph}{Implementation RL-MPC 5}{52}{equation.5.1.9}%
\contentsline {paragraph}{Implementation 6}{52}{equation.5.1.10k}%
\contentsline {subsection}{\numberline {5.1.2}Initial RL and MPC performance}{52}{subsection.5.1.2}%
\contentsline {section}{\numberline {5.2}Results - RL-MPC 1}{53}{section.5.2}%
\contentsline {section}{\numberline {5.3}Results - RL-MPC 2}{54}{section.5.3}%
\contentsline {section}{\numberline {5.4}Results - RL-MPC 3}{55}{section.5.4}%
\contentsline {section}{\numberline {5.5}Results - RL-MPC 4}{56}{section.5.5}%
\contentsline {section}{\numberline {5.6}Results - RL-MPC 5 and 6}{58}{section.5.6}%
\contentsline {section}{\numberline {5.7}Final Result and Conclusion}{58}{section.5.7}%
\contentsline {chapter}{\numberline {6}Stochastic RL-MPC}{61}{chapter.6}%
\contentsline {section}{\numberline {6.1}Initial RL and MPC Performance}{61}{section.6.1}%
\contentsline {section}{\numberline {6.2}Results - VF and Terminal Region}{63}{section.6.2}%
\contentsline {section}{\numberline {6.3}Conclusion}{64}{section.6.3}%
\contentsline {chapter}{\numberline {7}Computational Speed up of RL-MPC}{66}{chapter.7}%
\contentsline {section}{\numberline {7.1}Reducing Neurons and Hidden Layers}{66}{section.7.1}%
\contentsline {section}{\numberline {7.2}Taylor Approximation}{68}{section.7.2}%
\contentsline {section}{\numberline {7.3}Combined}{69}{section.7.3}%
\contentsline {section}{\numberline {7.4}Discussion and Conclusion}{69}{section.7.4}%
\contentsline {chapter}{\numberline {8}Discussion and Conclusion}{71}{chapter.8}%
\contentsline {section}{\numberline {8.1}Conclusion}{71}{section.8.1}%
\contentsline {section}{\numberline {8.2}Recommendations and Future Work}{72}{section.8.2}%
\contentsline {chapter}{References}{74}{chapter*.54}%
\contentsline {chapter}{\numberline {A}RL \& RL Training }{78}{appendix.A}%
\contentsline {section}{\numberline {A.1}Overview of RL Algorithms}{78}{section.A.1}%
\contentsline {section}{\numberline {A.2}Selection of RL Algorithm}{78}{section.A.2}%
\contentsline {section}{\numberline {A.3}Agent Training}{80}{section.A.3}%
\contentsline {section}{\numberline {A.4}Value Function Training}{80}{section.A.4}%
\contentsline {chapter}{\numberline {B}RL-MPC}{81}{appendix.B}%
\contentsfinish 

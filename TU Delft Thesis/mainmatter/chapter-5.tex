\chapter{Deterministic RL-MPC}
\label{chapter:deterministic_RL_MPC}

\emph{description of chapter}

\section{Implementation}
\emph{Explain the implementation of the deterministic case}
\subsection{RL-MPC problem formulations}

\emph{constuct the OCP of all the RL-MPC OCP's. (i.e. naive implementation of simply including the VF function, then with a terminal constraint and then with both)}
\subsection{Initial RL and MPC performance}
\emph{The performance of the selected RL and MPC Policy and explain the chosen ones}

\section{Case Study 1 - Initial Guesses from actor}
\emph{Show the effect of initial guesses from the actor, and how performance is affected by initial guesses.}

\section{Case Study 2 - Value Function addition}
\emph{Results of including the vf from the trained agent, a self-trained vf and initial guesses from actor, and then finally a reduced order self-trained vf}

\section{Case Study 3 - Terminal Constraint}
\emph{Results and discussion of using a terminal constraint from the actor as well as allowing a slight deviation from the terminal constraint}

\section{Case Study 4 - Value Function and Terminal Constraint}
\emph{The Results and discussion of combining the two}

\section{Final Result and Conclusion}
\emph{The final selected algorithm and conlusion on the work done}


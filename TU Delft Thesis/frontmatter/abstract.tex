\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Summary}


      The efficient operation of smart greenhouses is essential for enhancing crop yield while minimizing energy costs. This thesis investigates a hybrid control strategy that integrates Reinforcement Learning (RL) and Model Predictive Control (MPC) to optimize economic benefits in autonomous greenhouses. While previous research has explored the use of RL and MPC individually, this thesis examines the effect of modifying MPC’s objective function with terminal constraints and a cost function provided by an independently trained RL policy and value function respectively, tested in both deterministic and stochastic environments. This approach leverages RL's long-term planning and ability to handle uncertainties, combined with MPC’s online optimization, to improve overall control performance and robustness. Simulation results demonstrate a $24\%$ increase in performance over MPC and a $5\%$ improvement over RL at a 1 hour prediction horizon, with greater improvements over RL and less improvement over MPC at longer prediction horizons in a deterministic environment.  Additionally, RL trained in uncertain environments can transfer its understanding of uncertainty into the RL-MPC framework. This integration allows RL-MPC to maintain superior performance in low-uncertainty conditions while exhibiting greater robustness under higher uncertainties compared to MPC. To address the increased computational costs of RL-MPC, smaller neural networks  and Taylor approximation were employed for the value function, effectively reducing the computational burden without affecting performance.
      
      
      